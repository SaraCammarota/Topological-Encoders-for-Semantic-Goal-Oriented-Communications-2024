defaults:
  - dataset: imdb_binary
  - my_model: model_config
  - dgm: topk_dgm_conf
  - pooling: asa_conf
  - training: train_conf
  - exp: snr_conf
  - paths: default



hydra:
  sweeper:
    params:
      my_model.layers.n_pre: choice(2, 3)
      my_model.layers.n_post: choice(2, 3)
      my_model.layers.n_conv: choice(2, 3)
      my_model.layers.n_dgm_layers: choice(2, 3)
      my_model.layers.receiver: choice(2, 3)
      #my_model.dropout: choice(0.1, 0.2)         
      #training.lr: choice(0.001, 0.0005)   


# best configs with top-5 dgm:


#   best config previously found on mutag and topk pooling: val_loss, n_pre, n_post, n_conv, n_dgm_layers, lr   --->   0.347 2 1 2 2 5e-3

# with topk (and receiver gnn)
  #29 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=3  0.409


 #best config with sag on mutag
 #29 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=1 training.lr=0.0005 0.361   
  #12 : my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=2 training.lr=0.001


 # with asa
   #25 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=1 my_model.layers.n_dgm_layers=1 training.lr=0.0005  0.386
   #4 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=2 training.lr=0.001   0.418


# best configs with alpha dgm


#12 : my_model.layers.n_pre=1 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=1 training.lr=0.001    0.317




# on imdb binary
  
  #topk pooling
  
  #29 : my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=3 my_model.dropout=0.1 training.lr=0.0005    0.529 

  #sag pooling

  #8 : my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=2 my_model.dropout=0.1 training.lr=0.001     0.532

  #asa pooling

  #14 : my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=3 training.lr=0.0005   0.525



# on mutag, without noise in training
# asa
#25 : my_model.layers.n_pre=2 my_model.layers.n_post=3 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=2 training.lr=0.001
# sag
 #1 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=2 training.lr=0.0005
# topk
#26 : my_model.layers.n_pre=3 my_model.layers.n_post=3 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 training.lr=0.001   282 95 80
#28 : my_model.layers.n_pre=3 my_model.layers.n_post=3 my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=2 training.lr=0.001 328 95 81

# on proteins, without noise in training




# # # # # # # # # # # # BASELINE CONFIGURATION # # # # # # # # # # # #

baseline: 
  - dataset: 
  - my_model: kmeans
  - training: train_conf
  - exp: snr_conf
  - paths: default
