defaults:
  - dataset: mutag
  - my_model: model_config
  - dgm: topk_dgm_conf
  - pooling: topk_conf
  - training: train_conf
  - exp: snr_conf
  - paths: default




hydra:
  sweeper:
    params:
      my_model.layers.n_pre: choice(2, 3)
      my_model.layers.n_post: choice(1, 2)
      my_model.layers.n_conv: choice(1, 2, 3)
      my_model.layers.n_dgm_layers: choice(1, 2, 3)
      my_model.layers.receiver: choice(2, 3)
      #my_model.dropout: choice(0.1, 0.2)         
      #training.lr: choice(0.001, 0.0005)   
 
 

# best configs with top-5 dgm:


#   best config previously found on mutag and topk pooling: val_loss, n_pre, n_post, n_conv, n_dgm_layers, lr   --->   0.347 2 1 2 2 5e-3

# with topk (and receiver gnn)
  #29 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=3  0.409


 #best config with sag on mutag
 #29 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=1 training.lr=0.0005 0.361   
  #12 : my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=2 training.lr=0.001


 # with asa
   #25 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=1 my_model.layers.n_dgm_layers=1 training.lr=0.0005  0.386
   #4 : my_model.layers.n_pre=2 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=2 training.lr=0.001   0.418


# best configs with alpha dgm


#12 : my_model.layers.n_pre=1 my_model.layers.n_post=2 my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=1 training.lr=0.001    0.317




# on imdb binary
  
  #topk pooling
  
  #29 : my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=3 my_model.dropout=0.1 training.lr=0.0005    0.529 

  #sag pooling

  #8 : my_model.layers.n_conv=2 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=2 my_model.dropout=0.1 training.lr=0.001     0.532

  #asa pooling

  #14 : my_model.layers.n_conv=3 my_model.layers.n_dgm_layers=3 my_model.layers.receiver=3 training.lr=0.001   0.525

