GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
  | Name      | Type           | Params | Mode
-----------------------------------------------------
0 | pre       | MLP            | 1.2 K  | train
1 | gnn       | GNN            | 7.4 K  | train
2 | pool      | ASAPooling     | 1.2 K  | train
3 | noise     | NoiseBlock     | 0      | train
4 | graph_f   | DGM            | 4.2 K  | train
5 | post      | MLP            | 66     | train
6 | train_acc | BinaryAccuracy | 0      | train
7 | val_acc   | BinaryAccuracy | 0      | train
8 | test_acc  | BinaryAccuracy | 0      | train
-----------------------------------------------------
14.1 K    Trainable params
0         Non-trainable params
14.1 K    Total params
0.056     Total estimated model params size (MB)
64        Modules in train mode
0         Modules in eval mode
C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
C:\Users\HP\anaconda3\Lib\site-packages\torch_geometric\utils\sparse.py:268: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\b\abs_8f7uhuge1i\croot\pytorch-select_1717607507421\work\aten\src\ATen\SparseCsrTensorImpl.cpp:55.)
  adj = torch.sparse_csr_tensor(
Error executing job with overrides: []
Traceback (most recent call last):
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\main.py", line 65, in train
    trainer.fit(channel, train_dataloaders=train_loader, val_dataloaders=val_loader)
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 981, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\loops\utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\loops\evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\loops\evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\strategies\strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\my_model.py", line 129, in validation_step
    pred, _, _ = self(batch)
                 ^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\my_model.py", line 91, in forward
    x = self.noise(x, self.snr_db)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\layers.py", line 112, in forward
    snr_db = torch.tensor(snr_db).unsqueeze(0)
             ^^^^^^^^^^^^^^^^^^^^
TypeError: new(): invalid data type 'str'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Sanity Checking DataLoader 0:   0%|                                                                                                                                  | 0/1 [00:00<?, ?it/s]