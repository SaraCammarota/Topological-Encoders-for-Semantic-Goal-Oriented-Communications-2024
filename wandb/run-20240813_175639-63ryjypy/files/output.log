GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
  | Name      | Type           | Params | Mode
-----------------------------------------------------
0 | pre       | MLP            | 1.2 K  | train
1 | gnn       | GNN            | 7.4 K  | train
2 | pool      | SAGPooling     | 66     | train
3 | noise     | NoiseBlock     | 0      | train
4 | post      | MLP            | 66     | train
5 | train_acc | BinaryAccuracy | 0      | train
6 | val_acc   | BinaryAccuracy | 0      | train
7 | test_acc  | BinaryAccuracy | 0      | train
-----------------------------------------------------
8.7 K     Trainable params
0         Non-trainable params
8.7 K     Total params
0.035     Total estimated model params size (MB)
46        Modules in train mode
0         Modules in eval mode
C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Error executing job with overrides: []
Traceback (most recent call last):
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\main.py", line 68, in train_and_plot
    trainer.fit(channel, train_dataloaders=train_loader, val_dataloaders=val_loader)
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 981, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\loops\utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\loops\evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\loops\evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\trainer\call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\pytorch_lightning\strategies\strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\my_model.py", line 159, in validation_step
    pred, _, _ = self(batch)
                 ^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HP\OneDrive\Documenti\GitHub\with_hydra\my_model.py", line 101, in forward
    x = self.graph_f(x, data["edge_index"])
       ^^^^^^^^^^^^
  File "C:\Users\HP\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'Model_channel' object has no attribute 'graph_f'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Sanity Checking DataLoader 0:   0%|                                                               | 0/2 [00:00<?, ?it/s]